{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# device will determine whether to run the training on GPU or CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                          std=[0.2023, 0.1994, 0.2010])\n",
    "                                     ])\n",
    "# Create Training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "# Create Testing dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "# Instantiate loader objects to facilitate processing\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(images.shape)\n",
    "        print(labels.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_lables: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "label_counts: tensor([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000])\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for data in train_loader:\n",
    "    _, batch_labels = data\n",
    "    labels.extend(batch_labels.tolist())\n",
    "    \n",
    "labels_tensor = torch.tensor(labels)\n",
    "\n",
    "unique_labels, label_counts = torch.unique(labels_tensor, return_counts=True)\n",
    "\n",
    "print(f\"unique_lables: {unique_labels}\")\n",
    "print(f\"label_counts: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor([[-4.4874e-02,  4.3811e-02, -7.8075e-02, -3.7412e-02,  5.8519e-02,\n",
      "          3.2906e-02, -1.0355e-01,  5.7789e-02, -1.3436e-01, -8.9899e-02],\n",
      "        [-1.3819e-02,  2.0082e-02, -7.8813e-02,  5.6201e-03,  6.8872e-02,\n",
      "         -5.0184e-02, -9.7252e-02,  7.3458e-02, -1.1611e-01, -5.8291e-02],\n",
      "        [-4.3640e-02,  4.7339e-02, -6.3329e-02, -1.3951e-02,  4.7281e-02,\n",
      "         -1.3054e-02, -7.2078e-02,  4.2382e-02, -1.6601e-01, -5.8376e-03],\n",
      "        [-6.3164e-03,  1.9979e-02, -6.3245e-02, -1.4167e-02,  7.7432e-02,\n",
      "          1.2768e-03, -8.9522e-02,  5.8453e-02, -1.0551e-01, -5.0332e-02],\n",
      "        [-1.2298e-02, -9.7659e-03, -8.8244e-02, -1.4515e-02,  6.2635e-02,\n",
      "         -2.0959e-02, -1.0211e-01,  5.3557e-02, -1.2274e-01, -5.4545e-02],\n",
      "        [ 1.1532e-02,  2.1491e-02, -3.5479e-02,  1.0279e-02,  1.8643e-02,\n",
      "         -3.0367e-02, -1.1701e-01,  1.0353e-01, -1.7915e-01, -7.8921e-02],\n",
      "        [-1.5718e-02,  1.2292e-02, -5.4816e-02, -3.3840e-02,  9.8122e-02,\n",
      "         -7.1410e-03, -7.8745e-02,  8.4650e-02, -1.5188e-01, -5.0696e-02],\n",
      "        [-1.7721e-02, -1.5376e-02, -5.5398e-02, -3.7553e-02,  8.6766e-02,\n",
      "          1.6867e-03, -8.3420e-02,  6.5833e-02, -9.5762e-02, -3.9085e-02],\n",
      "        [-3.2852e-02,  1.9742e-05, -5.2019e-02, -3.2374e-02,  7.8801e-02,\n",
      "         -1.8455e-03, -7.8441e-02,  4.7569e-02, -1.1747e-01, -3.6827e-02],\n",
      "        [ 9.1589e-03,  1.2035e-02, -7.7645e-02, -9.9764e-03,  3.7957e-02,\n",
      "         -7.6851e-03, -1.0753e-01,  3.2435e-02, -1.6521e-01, -5.0180e-02],\n",
      "        [-4.9895e-04,  1.3003e-02, -7.4253e-02, -1.6259e-02,  7.7816e-02,\n",
      "         -3.5192e-02, -7.3970e-02,  4.8589e-02, -1.0664e-01, -4.1542e-02],\n",
      "        [-2.5627e-02, -4.5211e-02, -7.2747e-02,  2.2134e-02,  5.6357e-02,\n",
      "         -5.5803e-02, -1.1986e-01,  6.9566e-02, -1.7801e-01, -1.0229e-01],\n",
      "        [-1.9545e-02,  1.7405e-02, -6.6506e-02, -6.0876e-02,  6.6426e-02,\n",
      "          6.9237e-03, -9.4303e-02,  5.0038e-02, -1.2211e-01, -4.3242e-02],\n",
      "        [-1.0333e-02,  1.3407e-03, -8.7227e-02, -3.7520e-03,  4.1474e-02,\n",
      "         -5.3118e-03, -1.2180e-01,  5.5671e-02, -1.5060e-01, -5.1463e-02],\n",
      "        [-1.1386e-02,  2.2921e-02, -6.0864e-02, -1.8825e-02,  5.8757e-02,\n",
      "         -1.3638e-02, -7.7215e-02,  5.7640e-02, -9.2789e-02, -4.0645e-02],\n",
      "        [ 1.7284e-02, -3.4566e-02, -8.4631e-02,  4.3051e-02,  7.9802e-02,\n",
      "         -8.2355e-03, -8.6665e-02,  4.6178e-02, -1.2827e-01, -7.8813e-02],\n",
      "        [-4.0169e-02,  2.9666e-03, -5.5875e-02, -3.9087e-02,  9.2451e-02,\n",
      "          6.4111e-03, -7.8877e-02,  5.2206e-02, -1.1751e-01, -5.5966e-02],\n",
      "        [-7.1072e-02,  2.3127e-02, -5.3459e-02, -6.7288e-02,  4.3150e-02,\n",
      "         -7.3035e-02, -9.6976e-02,  7.1437e-02, -1.7380e-01, -1.1186e-01],\n",
      "        [ 3.2874e-03,  8.4463e-03, -9.5062e-02, -2.2294e-02,  3.9738e-02,\n",
      "         -1.9478e-02, -1.1207e-01,  3.5714e-02, -1.4854e-01, -6.2306e-02],\n",
      "        [-7.4949e-03, -8.2471e-03, -5.6071e-02, -2.7175e-02,  9.3383e-02,\n",
      "          1.0052e-02, -7.4416e-02,  6.4004e-02, -1.0297e-01, -2.1126e-02],\n",
      "        [ 1.8502e-02,  1.2408e-02, -6.2541e-02, -5.0368e-02,  5.2038e-02,\n",
      "         -3.8361e-02, -8.7685e-02,  4.0171e-02, -1.5396e-01, -9.4942e-02],\n",
      "        [-1.4950e-02,  8.2806e-03, -3.3346e-02, -3.2497e-02,  6.4448e-02,\n",
      "          8.5418e-03, -7.5231e-02,  7.8273e-02, -1.5053e-01, -3.2089e-02],\n",
      "        [-1.1383e-02, -7.6115e-03, -6.6208e-02, -2.7292e-02,  8.8305e-02,\n",
      "         -2.2531e-02, -8.2557e-02,  5.6041e-02, -9.4850e-02, -1.5265e-02],\n",
      "        [-2.0076e-02,  2.8630e-03, -6.4297e-02, -1.5733e-02,  6.9484e-02,\n",
      "         -4.8978e-02, -8.3265e-02,  6.8832e-02, -1.1336e-01, -7.5104e-02],\n",
      "        [-3.9183e-03, -1.5171e-02, -5.5339e-02, -9.6163e-03,  7.1547e-02,\n",
      "         -1.0856e-02, -8.1247e-02,  4.5446e-02, -9.5237e-02, -5.0346e-02],\n",
      "        [ 1.3502e-02,  2.4292e-02, -7.5332e-02,  3.5720e-03,  5.6282e-02,\n",
      "          9.0849e-03, -9.3983e-02,  5.5382e-02, -1.3892e-01, -3.0035e-02],\n",
      "        [-1.2560e-02,  6.7585e-02, -8.6815e-02, -3.2516e-02,  7.4761e-02,\n",
      "         -4.8572e-02, -6.4537e-02,  4.6447e-02, -1.3941e-01, -2.3981e-02],\n",
      "        [ 8.6012e-03,  3.3629e-02, -5.9038e-02, -3.2829e-02,  5.7231e-02,\n",
      "          5.3759e-02, -9.6892e-02,  4.4809e-02, -1.8098e-01, -3.1651e-02],\n",
      "        [-6.9143e-03,  5.7397e-02, -7.8898e-02, -1.7376e-02,  3.2227e-02,\n",
      "          1.1891e-02, -8.7657e-02,  4.2425e-02, -1.3286e-01, -3.2746e-02],\n",
      "        [-2.7971e-02,  9.6102e-03, -7.7353e-02, -4.2844e-02,  7.8955e-02,\n",
      "          1.3579e-02, -8.5733e-02,  7.1804e-02, -1.0924e-01, -4.3488e-02],\n",
      "        [-3.1030e-02,  1.1084e-02, -4.8929e-02, -1.8760e-02,  7.2809e-02,\n",
      "          1.5619e-02, -9.3591e-02,  5.5602e-02, -1.1298e-01, -2.2787e-02],\n",
      "        [-8.5171e-03, -1.2216e-02, -7.2178e-02, -2.3789e-02,  7.4842e-02,\n",
      "          2.7043e-02, -1.1510e-01,  8.6876e-02, -1.3893e-01, -2.4725e-02],\n",
      "        [-2.4856e-02, -8.3709e-03, -6.1565e-02, -2.6956e-02,  6.0899e-02,\n",
      "         -3.2476e-02, -4.7430e-02,  5.8327e-02, -1.5168e-01, -6.5168e-02],\n",
      "        [-4.5319e-03,  3.5199e-02, -7.0001e-02, -1.9870e-02,  7.0016e-02,\n",
      "         -6.7027e-03, -6.6955e-02,  4.9013e-02, -1.2655e-01, -6.5590e-02],\n",
      "        [-2.3614e-02,  2.6710e-02, -6.9117e-02, -1.6904e-02,  7.1877e-02,\n",
      "         -1.6468e-02, -6.9312e-02,  7.4611e-02, -1.5575e-01, -7.8780e-02],\n",
      "        [ 1.7793e-04, -5.1161e-03, -1.0147e-01,  1.4091e-02,  5.1335e-02,\n",
      "         -2.5778e-02, -1.2010e-01,  5.9883e-02, -1.4029e-01, -4.9745e-02],\n",
      "        [ 1.1344e-02,  1.7962e-02, -7.9721e-02, -2.4314e-02,  4.8729e-02,\n",
      "         -3.0434e-03, -8.5381e-02,  3.8347e-02, -1.3507e-01, -8.0810e-02],\n",
      "        [-1.7726e-02,  1.7537e-02, -9.9205e-02, -1.8228e-02,  7.6563e-02,\n",
      "         -5.7542e-03, -7.2782e-02,  7.9983e-02, -1.3165e-01, -8.6273e-02],\n",
      "        [ 6.1864e-03,  2.3973e-02, -4.3376e-02, -1.8236e-02,  5.6839e-02,\n",
      "          7.9436e-03, -9.8078e-02,  7.7447e-02, -1.4819e-01, -9.0861e-02],\n",
      "        [-2.7797e-02, -1.2415e-02, -8.5850e-02, -2.1485e-02,  8.3555e-02,\n",
      "         -4.3651e-02, -6.2290e-02,  7.1697e-02, -1.4457e-01, -7.5804e-02],\n",
      "        [-6.2914e-02, -2.6609e-02, -3.6382e-02, -7.2787e-02,  8.3388e-02,\n",
      "         -2.1186e-02, -5.0975e-02,  6.7229e-02, -1.9569e-01, -3.0192e-02],\n",
      "        [-2.3647e-02, -5.2666e-04, -7.1873e-02, -1.1567e-02,  7.6541e-02,\n",
      "         -3.0974e-02, -8.5362e-02,  7.7714e-02, -1.3253e-01, -8.1008e-02],\n",
      "        [ 2.2549e-02,  8.0613e-02, -8.2411e-02, -1.9360e-02,  9.5523e-03,\n",
      "         -3.7856e-02, -1.2376e-01,  6.3381e-02, -1.4059e-01, -1.0477e-01],\n",
      "        [-1.1345e-02,  4.1704e-02, -5.4594e-02, -1.9447e-02,  7.7873e-02,\n",
      "          2.4825e-02, -6.0575e-02,  3.9520e-02, -1.3716e-01, -5.6174e-02],\n",
      "        [-3.2149e-02,  3.6770e-02, -5.4714e-02, -3.1355e-02,  8.0064e-02,\n",
      "         -8.9223e-03, -7.9643e-02,  3.8569e-02, -1.2454e-01, -4.0047e-02],\n",
      "        [-3.5512e-02, -6.2107e-03, -5.9846e-02, -5.9923e-03,  6.8108e-02,\n",
      "          7.1801e-03, -9.3536e-02,  5.0797e-02, -1.0585e-01, -3.3584e-02],\n",
      "        [ 4.8853e-03,  5.1929e-04, -9.1300e-02, -3.5039e-02,  6.4394e-02,\n",
      "         -1.5731e-02, -6.9423e-02,  4.2124e-02, -1.1700e-01, -7.6172e-02],\n",
      "        [-9.0434e-03,  1.9098e-02, -7.9237e-02, -2.1366e-02,  5.8534e-02,\n",
      "         -2.0099e-02, -9.0923e-02,  2.2504e-02, -1.6786e-01, -6.3199e-02],\n",
      "        [-1.0918e-02,  5.9745e-02, -9.1714e-02, -5.8696e-03,  4.4163e-02,\n",
      "         -8.7352e-03, -1.2565e-01,  3.0576e-02, -1.5491e-01, -5.0682e-02],\n",
      "        [-2.8570e-02,  1.1354e-02, -6.3287e-02, -2.1421e-02,  6.2560e-02,\n",
      "         -4.7593e-03, -7.3022e-02,  6.2267e-02, -1.7020e-01, -3.6477e-02],\n",
      "        [-3.0437e-02,  8.8908e-04, -8.9001e-02,  2.4575e-03,  1.0039e-01,\n",
      "         -2.9216e-02, -7.9910e-02,  7.9836e-02, -1.1856e-01, -1.0435e-01],\n",
      "        [-2.2793e-02,  1.5107e-02, -6.4038e-02, -5.1546e-02,  6.6236e-02,\n",
      "          1.6888e-03, -6.7046e-02,  6.4957e-02, -1.2090e-01, -4.2728e-02],\n",
      "        [-2.1646e-02,  4.6496e-02, -4.7564e-02, -1.5596e-02,  4.9809e-02,\n",
      "         -3.8237e-02, -1.2434e-01,  7.6825e-02, -1.5156e-01, -9.1585e-02],\n",
      "        [-1.3015e-02,  5.7221e-02, -3.8581e-02, -7.2407e-03,  4.8941e-02,\n",
      "          2.6830e-02, -1.0130e-01,  8.9030e-03, -1.7510e-01, -3.3921e-02],\n",
      "        [-1.9263e-02,  4.1905e-03, -9.1418e-02, -2.6468e-02,  7.5108e-02,\n",
      "         -1.0293e-03, -6.3399e-02,  3.2370e-02, -1.1092e-01, -4.4497e-02],\n",
      "        [-1.5189e-02, -8.8130e-03, -6.3040e-02, -1.9973e-02,  8.1297e-02,\n",
      "          1.6903e-03, -7.8591e-02,  6.4974e-02, -9.7116e-02, -3.9345e-02],\n",
      "        [-1.7357e-02,  4.2564e-02, -2.9847e-02,  5.7360e-03,  8.5278e-02,\n",
      "          1.9988e-02, -8.8907e-02,  7.4536e-03, -1.5370e-01, -2.3497e-02],\n",
      "        [ 4.7307e-03, -4.5941e-03, -7.1216e-02,  4.5283e-02,  6.3079e-02,\n",
      "          8.6411e-04, -1.2317e-01,  7.8695e-02, -1.2876e-01, -1.0719e-01],\n",
      "        [-4.4174e-03,  3.1374e-02, -5.7891e-02, -9.7291e-03,  5.9095e-02,\n",
      "          2.0771e-03, -1.0559e-01,  2.3693e-02, -9.0184e-02, -4.0628e-02],\n",
      "        [-1.6105e-02,  1.0877e-02, -5.4811e-02, -5.0172e-02,  7.5246e-02,\n",
      "         -3.4151e-03, -7.2973e-02,  6.4009e-02, -1.1448e-01, -3.2743e-02],\n",
      "        [ 9.0056e-03,  1.2088e-02, -8.2027e-02, -1.4569e-02,  7.3484e-02,\n",
      "         -1.3059e-02, -8.3656e-02,  6.1281e-02, -1.0330e-01, -4.7235e-02],\n",
      "        [-2.5348e-04,  4.6688e-02, -8.4704e-02, -2.0725e-02,  1.2654e-02,\n",
      "         -1.2037e-03, -1.1898e-01,  5.8101e-02, -1.4861e-01, -3.7503e-03],\n",
      "        [-3.2291e-02,  2.1120e-02, -7.1280e-02, -2.6045e-02,  2.5040e-02,\n",
      "         -4.2568e-02, -1.0048e-01,  4.5448e-02, -1.0947e-01, -4.9553e-02],\n",
      "        [-1.2873e-02, -2.1477e-02, -4.5900e-02, -2.8228e-02,  6.6390e-02,\n",
      "         -3.8576e-03, -8.7102e-02,  4.8012e-02, -1.0746e-01, -2.7436e-02]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/20, Loss: 2.2986]\n"
     ]
    }
   ],
   "source": [
    "model = ConvNeuralNet(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        print(outputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break #Test\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}, Loss: {\"{:.4f}\".format(loss.item())}]')\n",
    "    break #Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 images: 82.798%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(f'Accuracy of the network on the {50000} images: {100 * correct / total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
